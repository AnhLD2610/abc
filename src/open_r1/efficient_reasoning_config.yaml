# Efficient Reasoning Training Configuration
# Enhanced GRPO with Contrastive Learning

# Model configuration
model_name_or_path: "Qwen/Qwen2.5-7B-Instruct"
model_revision: null

# Dataset configuration
dataset_mixture:
  datasets:
    - id: "lighteval/MATH"
      split: "train"
      weight: 0.7
    - id: "openai/gsm8k" 
      split: "train"
      weight: 0.3
  test_split_size: 0.1
  seed: 42

# Training arguments
output_dir: "./outputs/efficient_reasoning_grpo"
num_train_epochs: 3
per_device_train_batch_size: 4
per_device_eval_batch_size: 4
gradient_accumulation_steps: 4
learning_rate: 1e-5
lr_scheduler_type: "cosine"
warmup_ratio: 0.1

# GRPO specific parameters
num_generations: 8  # N samples per prompt
temperature: 0.8
top_p: 0.9
top_k: 50
max_prompt_length: 1024
max_completion_length: 512
beta: 0.01  # KL penalty
epsilon: 0.2  # PPO clip ratio

# Contrastive Learning Parameters (NEW)
contrastive_weight: 0.5  # Weight for supervised contrastive loss
infonce_weight: 0.3      # Weight for InfoNCE loss
contrastive_temperature: 0.1  # Temperature for contrastive learning
enable_length_reward_scaling: true  # Enable length penalty in rewards

# Efficient Reasoning Parameters (NEW)
length_weight: 0.3       # Weight for length penalty in reward
accuracy_weight: 0.7     # Weight for accuracy in reward
reward_threshold: 0.5    # Threshold for positive/negative classification

# Entropy Exploration Parameters (NEW)
difficulty_threshold: 0.3      # Success rate threshold for hard/easy classification
high_entropy_temperature: 1.2  # Higher temperature for hard questions
enable_entropy_exploration: true

# Logging and evaluation
logging_steps: 10
eval_steps: 100
save_steps: 500
save_total_limit: 3
evaluation_strategy: "steps"
load_best_model_at_end: true
metric_for_best_model: "eval_reward"
greater_is_better: true

# Mixed precision and optimization
bf16: true
dataloader_num_workers: 4
remove_unused_columns: false
group_by_length: false

# Reporting
report_to: ["tensorboard", "wandb"]
run_name: "efficient_reasoning_grpo_contrastive"

# Advanced options
push_to_hub: false
hub_model_id: null
hub_strategy: "every_save"